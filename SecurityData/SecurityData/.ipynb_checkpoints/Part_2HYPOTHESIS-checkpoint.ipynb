{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ryan Wahl, Joey Grzelak, Shayne Sibley \n",
    "\n",
    "Current hypothesis: \n",
    "    An IT administrator names Whilemina Shafira Perry was fired on what seems to be June 6. Then, on June 7, emails began being sent out without any attachments but that were large in size, from many different email accounts. We think that Whilemina wrote some sort of scipt to leak data if he were ever fired. He has the means to do so as an IT administrator, and do so from accounts that weren't his.\n",
    "    \n",
    "Next steps:\n",
    "    Look at the device logs to see if we can find any irregularities/see if he was logging into people's computers while they weren't there. Look at other fired employees to see if they took part in helping Whilemina. Look at current employees/IT administrators to see if he had help inside after he was fired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Initial hypotheses.** Analyze the data and identify initial hypotheses. One interesting challenge will be correlating the different data sets. Submit python Jupyter notebook(s) that document your analysis process so far (e.g. data processing, visualization, analytics; report all the various methods you tried, even if unfruitful or unsuccessful).  At the beginning of the primary notebook, list your team members, describe your current hypotheses, and list your planned next steps.  Use markdown to annotate your notebook(s). Submit any additional project materials in a zip.  Submit everything as a team through one team member."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weren't really sure where to start so we made a list of every employee who was fired every month by grouping the employee list by month and seeing who wasn't in the system the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy\n",
    "import matplotlib\n",
    "devinf = pandas.read_csv(\"device_info.csv\")\n",
    "emainf = pandas.read_csv(\"email_info.csv\")\n",
    "empinf = pandas.read_csv(\"employee_info.csv\")\n",
    "emainf = emainf.rename(columns = {'size':'sizeofemail'})\n",
    "htpinf = pandas.read_csv(\"http_info.csv\")\n",
    "loginf = pandas.read_csv(\"logon_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empbymonth = empinf.groupby('month')\n",
    "\n",
    "mayemp = empbymonth.get_group('5/1/17')\n",
    "juneemp = empbymonth.get_group('6/1/17')\n",
    "julyemp = empbymonth.get_group('7/1/17')\n",
    "augustemp = empbymonth.get_group('8/1/17')\n",
    "septemberemp = empbymonth.get_group('9/1/17')\n",
    "octoberemp = empbymonth.get_group('10/1/17')\n",
    "novemberemp = empbymonth.get_group('11/1/17')\n",
    "\n",
    "del mayemp['month']\n",
    "del juneemp['month']\n",
    "del julyemp['month']\n",
    "del augustemp['month']\n",
    "del septemberemp['month']\n",
    "del octoberemp['month']\n",
    "del novemberemp['month']\n",
    "\n",
    "empfiredmay = pandas.DataFrame()\n",
    "empfiredjune = pandas.DataFrame()\n",
    "empfiredjuly = pandas.DataFrame()\n",
    "empfiredaug = pandas.DataFrame()\n",
    "empfiredsept = pandas.DataFrame()\n",
    "empfiredoct = pandas.DataFrame()\n",
    "\n",
    "empfiredmay = pandas.merge(mayemp, juneemp, indicator='exist', how='left')\n",
    "empfiredmay['exist'] = numpy.where(empfiredmay.exist == 'both', True, False)\n",
    "empfiredmay = empfiredmay.loc[empfiredmay['exist'] == False]\n",
    "empfiredmay = empfiredmay.reset_index(drop=True)\n",
    "empfiredmay['exist'] = 'May'\n",
    "empfiredmay=empfiredmay.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "empfiredjune = pandas.merge(juneemp, julyemp, indicator='exist', how='left')\n",
    "empfiredjune['exist'] = numpy.where(empfiredjune.exist == 'both', True, False)\n",
    "empfiredjune = empfiredjune.loc[empfiredjune['exist'] == False]\n",
    "empfiredjune = empfiredjune.reset_index(drop=True)\n",
    "empfiredjune['exist'] = 'June'\n",
    "empfiredjune=empfiredjune.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "empfiredjuly = pandas.merge(julyemp, augustemp, indicator='exist', how='left')\n",
    "empfiredjuly['exist'] = numpy.where(empfiredjuly.exist == 'both', True, False)\n",
    "empfiredjuly = empfiredjuly.loc[empfiredjuly['exist'] == False]\n",
    "empfiredjuly = empfiredjuly.reset_index(drop=True)\n",
    "empfiredjuly['exist'] = 'July'\n",
    "empfiredjuly=empfiredjuly.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "empfiredaug = pandas.merge(augustemp, septemberemp, indicator='exist', how='left')\n",
    "empfiredaug['exist'] = numpy.where(empfiredaug.exist == 'both', True, False)\n",
    "empfiredaug = empfiredaug.loc[empfiredaug['exist'] == False]\n",
    "empfiredaug = empfiredaug.reset_index(drop=True)\n",
    "empfiredaug['exist'] = 'August'\n",
    "empfiredaug=empfiredaug.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "empfiredsept = pandas.merge(septemberemp, octoberemp, indicator='exist', how='left')\n",
    "empfiredsept['exist'] = numpy.where(empfiredsept.exist == 'both', True, False)\n",
    "empfiredsept = empfiredsept.loc[empfiredsept['exist'] == False]\n",
    "empfiredsept = empfiredsept.reset_index(drop=True)\n",
    "empfiredsept['exist'] = 'September'\n",
    "empfiredsept=empfiredsept.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "empfiredoct = pandas.merge(octoberemp, novemberemp, indicator='exist', how='left')\n",
    "empfiredoct['exist'] = numpy.where(empfiredoct.exist == 'both', True, False)\n",
    "empfiredoct = empfiredoct.loc[empfiredoct['exist'] == False]\n",
    "empfiredoct = empfiredoct.reset_index(drop=True)\n",
    "empfiredoct['exist'] = 'October'\n",
    "empfiredoct=empfiredoct.rename(columns = {'exist':'month_fired'})\n",
    "\n",
    "allemployeesfired = pandas.DataFrame()\n",
    "allemployeesfired = pandas.concat([empfiredmay, empfiredjune, empfiredjuly, empfiredaug, empfiredsept, empfiredoct])\n",
    "allemployeesfired = allemployeesfired.reset_index(drop=True)\n",
    "allemployeesfired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This got us a list of all of the employees who were fired and in what month they were fired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then tried to see if any employees were hired during this point by using this block of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing if any employees got hired... it doesn't look like it\n",
    "emphiredtest = pandas.DataFrame()\n",
    "emphiredtest = pandas.merge(juneemp, mayemp, indicator='exist', how='inner')\n",
    "emphiredtest['exist'] = numpy.where(emphiredtest.exist == 'both', True, False)\n",
    "emphiredtest = emphiredtest.loc[emphiredtest['exist'] == False]\n",
    "emphiredtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emphiredtest returns 0 employees so it doesn't seem that any employees were hired over the course of the 6 months. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then made a list of the employees who were employed in November (which means they had been employed throughout the period) and appended a list of the fired employees to get a list of unique employees and their user names for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalemployeelist = novemberemp.copy()\n",
    "finalemployeelist = finalemployeelist.append(allemployeesfired)\n",
    "finalemployeelist=finalemployeelist.rename(columns = {'user_id':'user'})\n",
    "del finalemployeelist['month_fired']\n",
    "namesandusers = finalemployeelist.loc[:,['employee_name', 'user']]\n",
    "namesandusers = namesandusers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then appended the names and users to the device logs, the website logs, and the login logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devinf = pandas.merge(devinf, namesandusers, how='left')\n",
    "htpinf = pandas.merge(htpinf, namesandusers, how='left')\n",
    "loginf = pandas.merge(loginf, namesandusers, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then looked at the different data sets to see if there was any obvious outliers in the data (tons of emails, lots of websites visited, lots of connections/disconnections, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a graph of the device connections/disconections by user..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnctbyuser = devinf.groupby('user')\n",
    "graphdeviceuse = pandas.DataFrame()\n",
    "graphdeviceuse['numcondis'] = cnctbyuser.size()\n",
    "graphdeviceuse = graphdeviceuse.sort_values(by=['numcondis'], ascending=False)\n",
    "%matplotlib inline\n",
    "graphdeviceuse.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows that most users connected a drive between 0 and 1250 times, while there were some users connecting between 1500 and 3000 times. The second group has a lot less people, a little suspicious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing the same for email use, starting with the number of emails sent by one user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailbyuser = emainf.groupby('from')\n",
    "graphemailuse = pandas.DataFrame()\n",
    "graphemailuse['numemailsent'] = emailbyuser.size()\n",
    "graphemailuse.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people sent from 0 - 500 emails, but there don't seen to be too many outliers. Might want to look at 1000+ frequency, and also run the same thing but on emails to a certain person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sticking with emails we'll graph the number of attachments people sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphemailuse['sumattach'] = emailbyuser.attachments.sum()\n",
    "graphemailuse.plot.hist('sumattach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people didn't send any attachments in their emails, might want to investigate those who sent 500+ total attachments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphemailuse['sizesum'] = emailbyuser.sizeofemail.sum()\n",
    "graphemailuse.plot.hist('sizesum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to be anything out of the ordinary here. Except a few very large email size totals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing on the logon information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logonbyuser = loginf.groupby('user')\n",
    "graphloguse = pandas.DataFrame()\n",
    "graphloguse['numlogon'] = logonbyuser.size()\n",
    "graphloguse = graphloguse.sort_values(by='numlogon', ascending=False)\n",
    "graphloguse.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people logged in between 225 and 500 or so times. There are a few people in the 1500-1900 range that we should look at later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the email information again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emainf = emainf.sort_values(by=['date'])\n",
    "emainf.sort_values(by=['sizeofemail'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm. Those emails look really large, they're all the same size, and they seem to be from many different people, to many of the same people. On the same date too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets focus on those emails that are the max size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigemails = emainf[emainf['sizeofemail'] == 85904]\n",
    "bigemails = bigemails.sort_values(by=['date'])\n",
    "bigemails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These large emails start on June 07, interesting. Lets go back and look at the employees fired in June to see if we can discover anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empfiredjune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An IT administrator would have access to many computers and many emails. Lets investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devinf[devinf['user'] == 'WSP0210']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! He seems to have been fired on June 6, and the large emails start on June 7! I don't think that is just a coincidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we are now, we think we have identified at least one bad actor and will investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#newtable= devinf.merge(empinf, how='inner', left_on='user', right_on='user_id')\n",
    "#newtable2 = emainf.merge(htpinf, how='inner', left_on='id', right_on='id')\n",
    "#emainf= emainf.sort_values(by =['size'])\n",
    "#newtable2 = emainf.append(htpinf)\n",
    "#newtable2 = newtable2.sort_values(by=['id'])\n",
    "#newtable3 = newtable2.append(htpinf)\n",
    "#newtable = newtable.sort_values(by=['date'])\n",
    "#newtable4 = newtable3.append(newtable)\n",
    "#newtable4 = newtable4.sort_values(by=['date'])\n",
    "#empinf['month'] = empinf.month[:1]\n",
    "#empinf['month']\n",
    "#empmonth = empinf.groupby('month')\n",
    "#empmonth.size()\n",
    "#empinf['month'] = empinf['month'].str.slice(0,1)\n",
    "#empinf = empinf.sort_values(by = ['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are some other things we have tried. We looked at many differnt sortings for the different data sets to see if there were any outliers, that is actually how we found that the size of the emails were identical and suspicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
